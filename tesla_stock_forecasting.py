# -*- coding: utf-8 -*-
"""TESLA STOCK FORECASTING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OCgJ63R9Ly7iyz5FBHFR_bBNVF13PbD1
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU
from tensorflow.keras.callbacks import EarlyStopping

from sklearn.metrics import mean_squared_error

#Verify the file path and name
data_dir = "/content/TSLA.csv"
# If the file is in the same directory as the notebook, you can use a relative path:
# data_dir = "TSLA.csv"

# Try using a raw string to avoid potential issues with backslashes
# data_dir = r"C:\Users\Dr. Joan\Downloads\TSLA.csv"

# Check if the file exists
import os
if not os.path.exists(data_dir):
    raise FileNotFoundError(f"File not found at: {data_dir}")

df = pd.read_csv(data_dir, index_col='Date')
df.head(10)

# Try using a raw string to avoid potential issues with backslashes
# data_dir = r"C:\Users\Dr. Joan\Downloads\TSLA.csv"

# Check if the file exists
import os
if not os.path.exists(data_dir):
    raise FileNotFoundError(f"File not found at: {data_dir}")

df = pd.read_csv(data_dir, index_col='Date')
df.head(10)

df.info()

dataset=df[['Close']]

dataset

dataset.shape

dataset.plot(figsize=(12,6))

train_size=int(0.8*len(dataset))
test_size=len(dataset)- train_size
print(f'Train Size: {train_size}')
print(f"Test Size: {test_size}")

data=dataset.values

train_df=data[:train_size,:]

test_df=data[train_size-60:,:]

def create_dataset(dataset, look_back=60):
    X, Y = [], []
    for i in range(look_back, len(dataset)):
        a = dataset[i-look_back:i, 0]
        X.append(a)
        Y.append(dataset[i, 0])
    return np.array(X), np.array(Y)

look_back = 60  # You can adjust this value

# Create the training dataset
x_train, y_train = create_dataset(train_df, look_back)

# Create the testing dataset
x_test, y_test = create_dataset(test_df, look_back)

# Now you can convert them to NumPy arrays if needed:
x_train = np.array(x_train)
y_train = np.array(y_train)

# Reshape x_train and x_test to include the feature dimension
x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)
x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)

# Now, rebuild your model with the corrected input shape:
model = Sequential([
    LSTM(64, return_sequences=True, activation='tanh', input_shape=(x_train.shape[1], x_train.shape[2])),  # Updated input_shape
    LSTM(32, return_sequences=False, activation='tanh'),
    Dense(64, activation='relu'),
    Dense(1, activation='linear')
])

model.compile(optimizer='adam', loss='mse')

model.fit(x_train,y_train,epochs=200)

# Creating a testing set with 60 time-steps and 1 output
x_test = []
y_test = []

for i in range(60, len(test_df)):
    x_test.append(test_df[i-60:i, 0])
    y_test.append(test_df[i, 0])

x_test, y_test = np.array(x_test), np.array(y_test)

predictions=model.predict(x_test)
predictions

train = dataset.iloc[:train_size , 0:1]
test = dataset.iloc[train_size: , 0:1]
test['Predictions'] = predictions

plt.figure(figsize= (16, 6))
plt.title('Tesla Close Stock Price Prediction', fontsize= 18)
plt.xlabel('Date', fontsize= 18)
plt.ylabel('Close Price', fontsize= 18)
plt.plot(train['Close'], linewidth= 3)
plt.plot(test['Close'], linewidth= 3)
plt.plot(test["Predictions"], linewidth= 3)
plt.legend(['Train', 'Test', 'Predictions'])
